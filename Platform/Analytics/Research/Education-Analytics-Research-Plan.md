# Research Plan for Education Analytics MVP -- draft
We want to test the Education Analytics MVP to determine if it helps Education Benefit product owners and stakeholders to quickly assess the health of their tools and identify gaps to further investigate. 

## Background
Based on a previous Insights and Analytics kickoff meeting, a Product Health prototype was created. We want to test the prototype with product owners and stakeholders to identify gaps and areas that need improvement.  

## Research Questions
1. Can product owners/stakeholders easily identify when products are up or down?
2. When a product owner identifies that a product is down or performing poorly, what is the next step?
3. Can product owners/stakeholders determine which product needs the most attention?
4. Do product owners/stakeholders understand metrics like Average Latency, Success/Error Rate, Total/Unique/Repeat Event, and Goal Conversion?
   - Are these the right metrics?
   - Which metrics are missing?
   - Which metrics are not helpful?
5. What do product owners/stakeholders expect to find when they drill in to a data point?
6. Do product owners/stakeholders understand the meanings of the various shades of red and green?
7. What devices do product owners/stakeholders prefer to use to when viewing analytics?
8. What are the expectations/requirements around sharing Insights and Analytics with other team members?
9. What are the expectations/requirements for report date and time range options?

## Hypothesis
TBD


## Method
1.	What method of research are you planning? 
  - **Sample Methodologies**: Directed interviews; ethnographic interviews; observation; card sorts; tree tests; guerilla usability testing; usability testing with low- or high-fidelity prototypes; user acceptance testing. 
  - **Also mention:** in-person moderated, remote moderated, remote unmoderated
  
2.	Why this method? How does this methodology help you answer your research questions? 

3.	Where are you planning to do your research? *If in person, mention the location, point of contact, arrangements, etc. If online, mention which tool you'll be using (GTM, Join.me, etc.)*

4.	What will you be testing? *(Design mocks, card sort, prototype, page, content, etc.)* 

## Participants and Recruitment
1.	Participant criteria: What are you looking for in a participant?
(Mention: Number of people, ages, accessibility preferences, geographical diversity, login requirements, VA benefit requirements, familiarity with technology, etc. Keep in mind, the more requirements, the more difficult the recruit, so give ample time to ensure the right participant mix.)

2.	What is your recruitment strategy? 
(If in person, describe how you will find participants. If remote, mention if you plan to draw from the existing recruiting contract or if there are other places where you would like to reach out to find participants specifically for this project. If you need help, please contact UX lead.)

## When? 
1.	Timeline: What dates do you plan to do research? 
(IF you are using the research recruiting contract, please submit 1 FULL week prior to the start of research for remote, 2+ weeks for in person.) 

2.	Prepare: When will the thing you are testing be ready? (Goes without saying, but should be a few days before testing will begin.) 

3. Length of Sessions: How long do you estimate each session will be? (This helps with scheduling & thank you gifts.) e.g. 30 minutes, < 1 hour, up to 2 hours, up to 4 hours) 

4.	Availability: If applicable, when would you like sessions scheduled? **Please list exact dates and times in EASTERN Standard Time**. Please request enough dates and time slots (e.g. Monday 9-1, 3-6; Tuesday 9-6, etc.). Be as flexible as possible, cognizant that many Veterans are only available before and after working times, and live across the U.S.

5.	Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 

## Team Roles
Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers.** 
- Moderator:
- Research guide writing and task development (usually but not always same as moderator):
- Participant recruiting & screening:
- Project point of contact:
- Participant(s) for pilot test:
- Note-takers:
- Observers:

**List email addresses for those who should attend and observe the sessions: VA Stakeholders, engineering team members, design team members, any other people who might find this research relevant to their work**

## Resources
- Project Brief: 
*Project brief should live in the appropriate vetsdotgov-team product folder, simply paste a link to it here*

- Discussion Guide
*Discussion guide should live in the appropriate vetsdotgov-team product folder, simply paste a link to it here*

- Notes & Recordings
*Session notes and recordings should live in the appropriate vetsdotgov-team product folder, simply place links to them here.*

- Synthesis
*Link to any documents used for synthesis (Mural or Realtimeboard boards, excel sheets, other data outputs, etc.)* 

- Lessons Learned
*Did you have any takeaways from the process of this research round that you want the team to remember for the future? Document them here.* 

- Read-Out/Results
  - *Read-out presentation should live in the appropriate product repo and folder; paste a link to it here.* 
  - ** Don't forget to add a link to your research folder to the research tracker! [https://github.com/department-of-veterans-affairs/vets.gov-team/blob/master/Practice%20Areas/Research/Research%20History.md](https://github.com/department-of-veterans-affairs/vets.gov-team/blob/master/Practice%20Areas/Research/Research%20History.md)
